{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2cbc42",
   "metadata": {},
   "source": [
    "# Practical example: Dunstaffnage weather record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef158984-4c0d-4479-a6cd-c84386840d12",
   "metadata": {},
   "source": [
    "We are going to look at some data from a weather station here at Dunstaffnage. \n",
    "\n",
    "We can quite easily use inbuilt functions to read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f532a-2c50-4812-a9b1-39525baecbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('dunstaffnagedata.txt', 'r').readlines()[0:10]\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a8f72-75aa-44cf-80ed-0ce4173d5116",
   "metadata": {
    "tags": []
   },
   "source": [
    "But we can't do very much analysis in this format. We can use the [Pandas](https://pandas.pydata.org/docs/index.html) module to do this.  Pandas is a powerful tool for working with tabular data, such as data stored in spreadsheets or databases. Pandas contains many inbuilt data structures to help you to explore, clean, and process your data. In pandas, a data table is called a DataFrame.\n",
    "\n",
    "We can import any module (in our environment) using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8f3d1-ff33-4096-afcc-2d8d7fd5096a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2703783-c6a0-42bb-a9c5-4b5b9348e377",
   "metadata": {},
   "source": [
    "#### Read data file to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4fd87-d8bf-4f1d-b0bd-32c070e00599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new column names\n",
    "col_names = [\"Year\", \"Month\", \"tmax\", \"tmin\",\"af\",\"rain\",\"sunhours\",\"recorder\"]\n",
    "\n",
    "df = pd.read_csv('dunstaffnagedata.txt',\n",
    "                 skiprows=7,\n",
    "                 names=col_names,\n",
    "                 sep='\\s+',\n",
    "                 na_values='---',\\\n",
    "                 index_col='time',\n",
    "                 parse_dates={'time':['Year','Month']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec9d9d-c19a-47aa-b1c0-a7bf7567d0a8",
   "metadata": {},
   "source": [
    "#### Print first 5 lines of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab993a44-72aa-45a8-8880-1fe40bcbccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1d829-7d8a-4610-b281-ee7ed5b58dd8",
   "metadata": {},
   "source": [
    "#### Print last 5 lines of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505cf8e-22fb-4e3a-87ae-2ad60f30b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57726974-c1ce-4e38-93da-1a55657df37d",
   "metadata": {},
   "source": [
    "#### Print data single timestep\n",
    "\n",
    "We can do this by indexing the time column, which we designateed as an index when we read the data in:\n",
    "\n",
    "    index_col='time'\n",
    "    \n",
    "The orginal data had two date-like columns **year** and **month**. We use a Pandas in-built parser to convert this to datetime data. \n",
    "\n",
    "    parse_dates={'time':['Year','Month']}\n",
    "    \n",
    "**Note:** The high level functions of each module such as `read_csv` in Pandas have very clear documentaion and exmaples. See [here](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81323b3-87f8-4352-a066-1af5e07dd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2022-10-01'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b90a3-565c-4b0a-9909-d5e8a342c09f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Show data for single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfa170-e5db-4ae0-b4de-318ea0fa4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05097f",
   "metadata": {},
   "source": [
    "#### Quick plot\n",
    "\n",
    "Pandas has lots of inbuilt functionality for plotting variables from the dataframe. For example, we can run some of these in the code block below.We can use pandas to quickly plot all the variables in the dataframe to get an overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b3b44-4417-4409-a0b2-4630f30e6243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.plot(subplots=True, layout=(2, 4), figsize=(12, 6), sharex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345b447-d237-4937-a6de-5d08614e63a1",
   "metadata": {},
   "source": [
    "#### Plot single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99fe32-5d7c-473d-aedb-3e91d11e6770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rain.plot(ylabel=\"Rain (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364a03a-c740-4a4c-a3ee-669e89994719",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782d92c-8c10-4759-bfc6-47ae76e2cf6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\"tmax\", \"tmin\"]\n",
    "df[columns].plot(ylabel=\"Temperature [degC]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e67f31-926d-499e-8b21-592a7849507e",
   "metadata": {},
   "source": [
    "#### Plot subset of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30428e9-28fe-4412-9167-a429a770a38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[columns]['1985':'2000'].plot(ylabel=\"Temperature [degC]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b275260-2d22-48ff-82c1-ff6a6299936b",
   "metadata": {},
   "source": [
    "That was pretty simple, and we are only using Pandas, but if we want to make any nicer plots, we will have to use Matplotlib. We wil also import numpy as we will want to use someof its fucntions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07249292-5f7f-4da7-8277-560ba164b638",
   "metadata": {},
   "source": [
    "#### Sub-set high precipitation months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4a492-db08-444b-8416-f0d371281917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55279e-15a0-40b1-92e2-d222b5861292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "df[df.rain>300].rain.plot(style='o',ms=10)\n",
    "plt.ylabel('Precipitation [mm/month]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b6693-0ffb-4cd5-936b-74ab75ff7868",
   "metadata": {},
   "source": [
    "#### Create a monthly precipitation climatology\n",
    "\n",
    "First we take an index of the months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f71b4e-1a09-4d11-98fd-3c47e525f3a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMonth=df.index.month\n",
    "rain_mm = df.groupby(IMonth)['rain'].mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f5380-5343-43f5-8b3a-2c43d4934282",
   "metadata": {},
   "source": [
    "You can type `Imonth` or `print(IMonth)`. If you want to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c436cd-5211-4ede-8872-d749b9714eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(rain_mm.cumsum(),'k--')\n",
    "ax.set_ylabel('Precipitation [mm]')\n",
    "ax.set_xlabel('Month')\n",
    "ticklabels = df.loc['2000'].index.strftime('%b')\n",
    "ax.set_xticks(np.arange(1,13))\n",
    "ax.set_xticklabels(ticklabels) # add monthlabels to the xaxis\n",
    "ax.set_title('Cumulative monthly precipitation climatology: {}-{}'.format(df.index.year[0],df.index.year[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b2696",
   "metadata": {},
   "source": [
    "Now lets do some data processing and analysis.\n",
    "\n",
    "Below we will average the existing tmax and tmin variables to give an estimate of the monthly average temperature (***Disclaimer:*** this probably isn't a very good estimate for average monthly temperature!). We will then interpolate missing values and apply a 12 month moving average before plotting. Finally, we will plot the monthly temperature climatology over the whole record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07447ef5-1834-4ac3-8968-cf4b22161613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average tmax and tmin columns to give monthly average temperature (tavg)\n",
    "columns = [\"tmax\", \"tmin\"]\n",
    "df['tavg'] = df[columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55386ada-a55b-4bd7-88db-417dac101b33",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot 12-month rolling averaged min, max and average temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bed27c-a363-4d25-a8c5-6cb81d73e330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set figure dimensions\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# apply statistcs \n",
    "df['tavg'].interpolate().rolling(window=12).mean().plot(color='k')\n",
    "df['tmax'].interpolate().rolling(window=12).mean().plot(color='r')\n",
    "df['tmin'].interpolate().rolling(window=12).mean().plot(color='b')\n",
    "\n",
    "# add a legend\n",
    "plt.legend(['Average Temp','Max Temp','Min Temp'],frameon=False,loc='best')\n",
    "\n",
    "# add a y-label\n",
    "plt.ylabel('Temperature [degC]')\n",
    "\n",
    "# add a title\n",
    "plt.title('12-month rolling averaged temperatures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010d03e-c053-41bd-b53e-4e4a66b2b9c9",
   "metadata": {},
   "source": [
    "#### Average by month to produce monthly climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f19c89-43d8-462d-8080-284c1947e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavg_mm=df.groupby(df.index.month)['tavg'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(tavg_mm,'b')\n",
    "ax.set_ylabel('Temperature [degC]')\n",
    "ax.set_xlabel('Month')\n",
    "\n",
    "# add a grid \n",
    "plt.grid()\n",
    "\n",
    "# set title \n",
    "ax.set_title('Monthly temperature climatology: {}-{}'.format(df.index.year[0],df.index.year[-1]))\n",
    "\n",
    "# set tick labels\n",
    "ticklabels = df.loc['2000'].index.strftime('%b') # add month xtick labels\n",
    "ax.set_xticks(np.arange(1,13))\n",
    "ax.set_xticklabels(ticklabels) #add monthlabels to the xaxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad7c43",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cdaf5",
   "metadata": {},
   "source": [
    "Now for some statistics. Here we apply a linear regression on time and average temperature to calculate the warming trend at Dunstaffnage during the record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23c091-95dd-4cf0-adef-efe422fd719e",
   "metadata": {},
   "source": [
    "##### Interpolate missing values, apply 12 month moving average and remove NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688c53b-520b-4da3-8cbb-fd169c31e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavg=df['tavg'].interpolate().rolling(window=12).mean().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb145176-1a06-460d-8543-bb55c272c7eb",
   "metadata": {},
   "source": [
    "Compute days since the first date in the index and convert this to decades for the time variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7caa1-f078-47d7-93fc-189ea332a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = (tavg.index - tavg.index[0])\n",
    "days = delta.days\n",
    "decades = days/365/10 # convert to decades so we get the slope estimate in temperature change per decade\n",
    "\n",
    "x = decades\n",
    "y = tavg.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e0a0c-45ed-4736-b4ba-618959b4e2b4",
   "metadata": {},
   "source": [
    "#### The regression\n",
    "\n",
    "We'll need `stats` from the SciPy module for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96b545-19b4-4f5f-9a02-ebd2009e3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9088da8-3039-4651-94fd-933614bd2e0e",
   "metadata": {},
   "source": [
    "To get help on a function you can type it's name followed by '?' to print the functions docstring. \n",
    "Adding '??' to the end of the function name will print the raw python code so you can look in detail what the function is doing 'under the hood'\n",
    "\n",
    "    stats.linregress??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3a7d6-be77-4c3c-8066-162e8a294e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print(\"slope: %f, intercept: %f\" % (slope, intercept))\n",
    "print(\"R-squared: %f\" % r_value**2)\n",
    "\n",
    "# Plot the data with a trend line\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df.index[0]+delta, y, 'o', label='original data')\n",
    "plt.plot(df.index[0]+delta, intercept + slope*x, 'r', label='fitted line')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# print the regression after the figure\n",
    "print('Temperature trend at Dunstaffnage is {} degrees per decade'.format(round(slope,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6d687",
   "metadata": {},
   "source": [
    "As an example of signal processing using SciPy, we will calculate the discrete Fourier transform on our average temperature data using the SciPy FFTpack module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89055da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "import datetime\n",
    "\n",
    "# first clean the data by interpolating missing points and removing any remaining NaN's\n",
    "data = df['tavg'].interpolate().dropna() \n",
    "\n",
    "#print(data.values) # sometimes need to extract data from a structure using .values\n",
    "#print(data)\n",
    "\n",
    "temp_fft = sp.fftpack.fft(data.values) # Return discrete Fourier transform\n",
    "\n",
    "temp_psd = np.abs(temp_fft) ** 2\n",
    "\n",
    "fftfreq = sp.fftpack.fftfreq(len(temp_psd), 1. / 12) # sample frequencies for monthly data\n",
    "\n",
    "i = fftfreq > 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax.plot(fftfreq[i], 10 * np.log10(temp_psd[i]))\n",
    "ax.set_xlim(0, 5)\n",
    "ax.set_xlabel('Frequency (1/year)')\n",
    "ax.set_ylabel('PSD (dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5bc37",
   "metadata": {},
   "source": [
    "Because the fundamental frequency of the signal is the yearly variation of the temperature (the seasonal cycle), we observe a clear peak at f=1 cycle/year. \n",
    "\n",
    "We can cut out frequencies higher than the fundamental frequency and perform an inverse FFT to convert the modified Fourier transform back to the temporal domain. This way, we recover a smoothed version of the signal (because the fast variations have been lost when we removed the high frequencies in the Fourier transform) that mainly contains the fundamental frequency, as shown in the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fft_bis = temp_fft.copy()\n",
    "temp_fft_bis[np.abs(fftfreq) > 1.1] = 0\n",
    "\n",
    "temp_slow = np.real(sp.fftpack.ifft(temp_fft_bis))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "#data.plot(ax=ax,color='b',lw=1.0, label='Original signal')\n",
    "ax.plot(data, color='b', linewidth=1.0)\n",
    "ax.plot(data.index,temp_slow, 'Orange', '-')\n",
    "ax.set_xlim(datetime.date(1994, 1, 1),datetime.date(2000, 1, 1))\n",
    "ax.legend(['Original signal','Filtered signal'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Mean temperature')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972bde0",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca475d1",
   "metadata": {},
   "source": [
    "Lets finish by calculating some comparison statistics from the dataset. We will first plot the correlation matrix across all variables in the dataframe using Pandas inbuilt pairwise correlation of columns function. This exploratory data analysis will inform how we then progress with analysing the data in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44645109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlation matrix across all variables in dataframe\n",
    "\n",
    "print('Correlation matrix: \\n{}'.format(df.corr()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544fe85",
   "metadata": {},
   "source": [
    "We see that there is a relativly strong negative correlation of -0.64 between sunlight hours and rainfall (as you might expect!). \n",
    "\n",
    "We can dig into this relationship a little deeper using NumPy and SciPy to calculate the comparison statistics and fit a linear regression to compare the observed monthly sunlight hours with the monthly rainfall total for the decade 1987-1997."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855c94a-02a2-4b78-b353-c5bdf6933244",
   "metadata": {},
   "source": [
    "#### Extract and clean sunhours and rain between 1987 and 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea1650-96ac-4c27-826b-7d350a48ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['sunhours','rain']\n",
    "data=df[columns]['1987':'1997'].interpolate().dropna() \n",
    "\n",
    "plt.scatter(data['sunhours'].values,data['rain'].values)\n",
    "plt.xlabel('Hours of Sunshine per month')\n",
    "plt.ylabel('Precipitation [mm/month]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff1f4e-edcd-4f61-bd4a-be3d3417a83d",
   "metadata": {},
   "source": [
    "#### Compare the correlations calculated by NumPy and SciPy methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1fdc0-c779-47ea-96a4-5e2bc1b426a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw data arrays\n",
    "x = data['sunhours'].values\n",
    "y = data['rain'].values \n",
    "\n",
    "r = np.corrcoef(x, y) # NumPy correlation coefficient\n",
    "print('NumPy Corelation coefficient = {}'.format(r[0, 1]))\n",
    "\n",
    "r = stats.pearsonr(x, y) # SciPy Pearson correlation coefficient and p-value. See 'stats.pearsonr?' for more detail\n",
    "print('SciPy Pearson R = {}'.format(r[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a90bf1-cfcd-4d05-bced-76e97d1dcf11",
   "metadata": {},
   "source": [
    "#### Print linear regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63e933-4448-45b4-a098-64d281992874",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stats.linregress(x, y)\n",
    "print('Regression slope = {}'.format(result.slope))\n",
    "print('Regression intercept = {}'.format(result.intercept))\n",
    "print('Regression pvalue = {}'.format(result.pvalue))\n",
    "print('Regression standard error = {}'.format(result.stderr))\n",
    "print('Regression R^2 = {}'.format(result.rvalue**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ada8b",
   "metadata": {},
   "source": [
    "From this comparison it seems reasonable to assume that months with more sunlight hours will have less rainfall; looking at the R^2 value, 35% of the variance in rainfall can be explained by variability in sunlight. We will now take this a little further and see if we can predict rainfall from sunlight hours by fitting a linear regression model from the scikit-learn module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7a00a",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07812f80",
   "metadata": {},
   "source": [
    "Scikit-learn (or sklearn) is a powerful module designed for machine learning in Python. Sklearn is built on NumPy, SciPy, and matplotlib and provides simple and efficient tools for predictive data analysis. Below we will fit a linear model to the data (similar to what we did above using SciPy) but then use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525da002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = x[:, np.newaxis] # Use only one feature\n",
    "\n",
    "reg = LinearRegression().fit(X, y) # Sanity check: The values below should look very similar to the values calculated using the SciPy stats.linregress method above.\n",
    "print('Regression R^2 = {}'.format(reg.score(X, y)))\n",
    "print('Regression slope: {}'.format(reg.coef_[0]))\n",
    "print('Regression intercept: {}'.format(reg.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0d748",
   "metadata": {},
   "source": [
    "Notice that the slope and intercept are nearly identical to the values calculated using the SciPy method (good news!). We can now divide the data into a training and test set and use scikit-learn to fit a linear model to the training set and use the test set to assess the accuracy of the predictions (and, finally, make a prediction of monthly precipitation from sunlight hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb61f5-d37b-4ac3-90d4-8e1dd6fc8fff",
   "metadata": {},
   "source": [
    "#### Write a predictive regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9718360-2a5f-468b-a012-9424ef539504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = x[:, np.newaxis] # Use only one feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f99a7-fce6-4e6e-b8e2-1867df7ead0a",
   "metadata": {},
   "source": [
    "#### Splitting the datasets into training and testing sets (you could do this manually, i.e. X_train = X[:-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc6d85-8a31-4c1a-90d8-453b979d68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.3)\n",
    "\n",
    "# Create linear regression object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test, color=\"black\", label='observations')\n",
    "plt.plot(X_test, y_pred, color=\"blue\", linewidth=3, label='prediction')\n",
    "plt.xlabel('Sunlight hours per month')\n",
    "plt.ylabel('Precipitation [mm/month]')\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "# Running Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "predictions = model.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r^2 is: ', r2)\n",
    "print('The RMSE is: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcb9fa-2423-4063-a966-83ce84de8e8d",
   "metadata": {},
   "source": [
    "#### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61a4ff-0a01-41fa-8458-96069491cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sunhours = 100\n",
    "prediction = model.predict(np.array([[monthly_sunhours]]))[0]\n",
    "print('For a month with {} hours of sunlight, I would predict there to be {} mm of rain'.format(int(monthly_sunhours),np.round(prediction,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e154d-71af-440c-bdee-71e709a75109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
