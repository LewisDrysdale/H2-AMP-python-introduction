{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158f9939",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be10e3a",
   "metadata": {},
   "source": [
    "Python virtual environments are used to create and manage separate environments for your Python projects (isolated environments for different projects). Python has a unique way of downloading, storing, and resolving packages (or modules).\n",
    "\n",
    "First lets create a python environment with the neccessary dependencies to do some work. We will run the following code in your Anaconda Prompt window (a terminal provided with the Anaconda package). \n",
    "\n",
    "We will use conda to do this but you could also use pip or easy_install. I find conda and the anaconda distribution easiest and most transparent for managing your python distribution. (I have downloaded Anaconda on each workstation so you can take a look at the packages it provides, especially Spyder, which is a 'MATLAB-like' gui for writting and running scripts.)\n",
    "\n",
    "The second line of code activates the new environment and the third line opens a jupyter notebook."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0032542b",
   "metadata": {},
   "source": [
    "conda create -n h2amp python=3.6 scipy jupyter numpy matplotlib pandas xarray scikit-learn\n",
    "conda activate h2amp\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae71824",
   "metadata": {},
   "source": [
    "# Python modules and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e080014",
   "metadata": {},
   "source": [
    "In python you need to import the modules that you want to use (modules are similar to toolboxes in MATLAB). There are modules for just about anything you want to do.\n",
    "\n",
    "A module is essentially a file containing a set of functions, known as python definitions and statements (like MATLAB functions). Modules are an extension on Python rather than separate programming languages, using Python syntax. You can import an entire module or individual definitions (functions) from a module to use in the main workspace. There are hundreds of modules available and you can also write your own modules to optimize your own workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# from math import sqrt, pi # only import sqrt function and pi from math module rather than whole module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e722ec6",
   "metadata": {},
   "source": [
    "# Basic math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be1f00",
   "metadata": {},
   "source": [
    "Python has in built math functions as well as a math (and numpy) modules for basic arithmetic. The code block below demonstrates some basic examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd27eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = min(5, 10, 25)\n",
    "y = max(5, 10, 25)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "x = abs(-7.25)\n",
    "\n",
    "print(x)\n",
    "\n",
    "x = pow(4, 3)\n",
    "\n",
    "print(x)\n",
    "\n",
    "x = math.sqrt(64)\n",
    "# x = sqrt(64) # if sqrt has been imported from the math module\n",
    "\n",
    "print(x)\n",
    "\n",
    "x = math.ceil(1.4)\n",
    "y = math.floor(1.4)\n",
    "\n",
    "print(x) \n",
    "print(y) \n",
    "\n",
    "x = math.pi\n",
    "# x = pi\n",
    "\n",
    "print(x)\n",
    "\n",
    "r = 5\n",
    "area = math.pi * r**2\n",
    "f\"Area of a Circle = {math.pi:.4} * {r}**2 = {area:.4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaaa725",
   "metadata": {},
   "source": [
    "# NumPy and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b45e5",
   "metadata": {},
   "source": [
    "NumPy (Numerical Python) is an open source Python library for scientific and numeric computing that lets you work with multi-dimensional arrays far more efficiently than Python alone. NumPy aims to provide an array object that is up to 50x faster and takes a lot less memory that traditional Python lists.\n",
    "\n",
    "NumPy is often used along with packages like SciPy (Scientific Python) and Matâˆ’plotlib (plotting library). This combination of NumPy, SciPy and Matplotlib is widely used as a free open-source replacement for MATLAB (the syntax is also very similar). \n",
    "\n",
    "Below we will generate some data using NumPy and plot with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.linspace(-np.pi, np.pi, 256)\n",
    "C, S = np.cos(X), np.sin(X)\n",
    "\n",
    "# Python indexing (starts at 0!)\n",
    "\n",
    "print(X[0])\n",
    "print(X[-1])\n",
    "print(C[10:20])\n",
    "\n",
    "plt.plot(X, C)\n",
    "plt.plot(X, S)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea088872",
   "metadata": {},
   "source": [
    "# Conditional loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = 56.5\n",
    "if abs(latitude) < 23.5:\n",
    "    print('Tropical')\n",
    "elif abs(latitude) > 66.5:\n",
    "    print('Polar')\n",
    "else:\n",
    "    print('Mid-latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116a9f6",
   "metadata": {},
   "source": [
    "# Definitions (Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latitude_band(latitude):\n",
    "    \"\"\"\n",
    "    print latitude zone for a given latitude\n",
    "    \"\"\"\n",
    "    text='degrees latitude you are in the'\n",
    "    if latitude == 0.0:\n",
    "        print('You are on the Equator!')\n",
    "    if abs(latitude) > 90:\n",
    "        raise Exception(\"Sorry, this is not a real latitude\")\n",
    "    elif latitude == 90:\n",
    "        print('You are at the North Pole')\n",
    "    elif latitude == -90:\n",
    "        print('You are at the South Pole')\n",
    "    elif abs(latitude) < 23.5:\n",
    "        print('At {} {} Tropics'.format(latitude,text))\n",
    "    elif abs(latitude) > 66.5:\n",
    "        print('At {} {} Polar regions'.format(latitude,text))\n",
    "    else:\n",
    "        print('At {} {} Mid-latitudes'.format(latitude,text))\n",
    "\n",
    "#latitude_band?\n",
    "\n",
    "latitude_band(45)\n",
    "\n",
    "#latitude_band(100)\n",
    "\n",
    "for lat in np.arange(-90,91,10): \n",
    "    latitude_band(lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f637cb",
   "metadata": {},
   "source": [
    "# SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7577d6e",
   "metadata": {},
   "source": [
    "SciPy (Scientific Python) has inbuilt functions for most/all statistical operations. Here we will use NumPy to generate some periodic data, SciPy to do some curve fitting and matplotlib to visulize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve fit example (https://programming-review.com/python/scipy-examples)\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "x_data = np.linspace(-5, 5, num=50)\n",
    "y_data = 2.9 * np.sin(1.5 * x_data) + np.random.normal(size=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "def test_func(x, a, b):\n",
    "    return a * np.sin(b * x)\n",
    "\n",
    "params, params_covariance = optimize.curve_fit(test_func, x_data, y_data, p0=[2, 2])\n",
    "print(params)\n",
    "ax.scatter(x_data,y_data)\n",
    "ax.plot(x_data, test_func(x_data,params[0], params[1]), c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef218be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation time\n",
    "\n",
    "#from scipy.interpolate import interp1d\n",
    "#interpolation_time = np.linspace(-5, 5, 20)\n",
    "\n",
    "#linear_interp = interp1d(x_data, y_data)\n",
    "#linear_results = linear_interp(interpolation_time)\n",
    "\n",
    "#cubic_interp = interp1d(x_data, y_data, kind='cubic')\n",
    "#cubic_results = cubic_interp(interpolation_time)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(x_data,y_data)\n",
    "#ax.plot(interpolation_time, linear_results, c='r', label='linear results')\n",
    "#ax.plot(interpolation_time, cubic_results, c='g', label='cubic results')\n",
    "\n",
    "#ax.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2cbc42",
   "metadata": {},
   "source": [
    "# Practical example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c8b81",
   "metadata": {},
   "source": [
    "Now lets look at some real data...\n",
    "\n",
    "We will use the pandas module to load some example Dunstaffnage weather data (dunstaffnagedata.txt). Pandas is a powerful tool for working with tabular data, such as data stored in spreadsheets or databases. Pandas contains many inbuilt data structures to help you to explore, clean, and process your data. In pandas, a data table is called a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = [\"Year\", \"Month\", \"tmax\", \"tmin\",\"af\",\"rain\",\"sunhours\",\"recorder\"]\n",
    "df = pd.read_csv('dunstaffnagedata.txt',skiprows=7,names=col_names,sep='\\s+',na_values='---',\\\n",
    "           index_col='time',parse_dates={'time':['Year','Month']})\n",
    "\n",
    "# print first 5 lines of dataset\n",
    "df.head() \n",
    "\n",
    "# print last 5 lines of dataset\n",
    "# df.tail() \n",
    "\n",
    "# print data single timestep\n",
    "# df.loc['2009-06'] \n",
    "\n",
    "# df.rain # show data for single variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05097f",
   "metadata": {},
   "source": [
    "Lets quickly plot all the variables in the dataframe to get an overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736316eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "df.plot(ax=ax, subplots=True, layout=(7,1)) # quick subplot of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99f407",
   "metadata": {},
   "source": [
    "Pandas has lots of inbuilt functionality for plotting variables from the dataframe. We run some of these in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e816e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.dates as mdates\n",
    "\n",
    "df.rain.plot() # plot single variable\n",
    "\n",
    "# plot sub-set of variables\n",
    "\n",
    "columns = [\"tmax\", \"tmin\"]\n",
    "#plt.figure(figsize=(8,6))\n",
    "df[columns].plot()\n",
    "plt.ylabel('Temperature [degC]')\n",
    "\n",
    "# plot subset of years\n",
    "\n",
    "#plt.figure(figsize=(8,6))\n",
    "df[columns]['1985':'2000'].plot()\n",
    "plt.ylabel('Temperature [degC]')\n",
    "\n",
    "# Sub-set high precipitation months\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "df[df.rain>300].rain.plot(style='o',ms=10)\n",
    "plt.ylabel('Precipitation [mm/month]')\n",
    "\n",
    "# Create a monthly precipitaion climatology\n",
    "\n",
    "rain_mm = df.groupby(df.index.month)['rain'].mean() \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(rain_mm.cumsum(),'k--')\n",
    "ax.set_ylabel('Precipitation [mm]')\n",
    "ax.set_xlabel('Month')\n",
    "ticklabels = df['2000'].index.strftime('%b')\n",
    "ax.set_xticks(np.arange(1,13))\n",
    "ax.set_xticklabels(ticklabels) # add monthlabels to the xaxis\n",
    "ax.set_title('Cumulative monthly precipitation climatology: {}-{}'.format(df.index.year[0],df.index.year[-1]))\n",
    "\n",
    "# plt.figure()\n",
    "# df.rain.hist() # plot histogram of precipitation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b2696",
   "metadata": {},
   "source": [
    "Now lets do some data processing. Below we will average the existing tmax and tmin variables to give an estimate of the monthly average temperature (this probably isn't a very good estimate for average monthly temperature!). We will then interpolate missing values and apply a 12 month moving average before plotting. Finally, we will plot the monthly temperature climatology over the whole record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6384db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average tmax and tmin columns to give monthly average temperature (tavg)\n",
    "\n",
    "columns = [\"tmax\", \"tmin\"]\n",
    "df['tavg'] = df[columns].mean(axis=1)\n",
    "\n",
    "# Plot 12-month rolling averaged min, max and average temperatures\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "df['tavg'].interpolate().rolling(window=12).mean().plot(color='k')\n",
    "df['tmax'].interpolate().rolling(window=12).mean().plot(color='r')\n",
    "df['tmin'].interpolate().rolling(window=12).mean().plot(color='b')\n",
    "plt.legend(['Average Temp','Max Temp','Min Temp'],frameon=False,loc='best')\n",
    "plt.ylabel('Temperature [degC]')\n",
    "plt.title('12-month rolling averaged temperatures')\n",
    "\n",
    "# Average by month to produce monthly climatology\n",
    "\n",
    "tavg_mm=df.groupby(df.index.month)['tavg'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(tavg_mm,'b')\n",
    "ax.set_ylabel('Temperature [degC]')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_title('Monthly temperature climatology: {}-{}'.format(df.index.year[0],df.index.year[-1]))\n",
    "ticklabels = df['2000'].index.strftime('%b') # add month xtick labels\n",
    "ax.set_xticks(np.arange(1,13))\n",
    "ax.set_xticklabels(ticklabels) #add monthlabels to the xaxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad7c43",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cdaf5",
   "metadata": {},
   "source": [
    "Now for some statistics. Here we apply a linear regression (using the SciPy stats module) on time and average temperature to calculate the warming trend at Dunstaffnage during the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# interpolate missing values, apply 12 month moving average and remove NaN's\n",
    "\n",
    "tavg=df['tavg'].interpolate().rolling(window=12).mean().dropna()\n",
    "\n",
    "# compute days since the first date in the index and convert this to decades for the time variable\n",
    "\n",
    "delta = (tavg.index - tavg.index[0])\n",
    "days = delta.days\n",
    "decades = days/365/10 # convert to decades so we get the slope estimate in temperature change per decade\n",
    "\n",
    "x = decades\n",
    "y = tavg.values\n",
    "\n",
    "# The regression\n",
    "\n",
    "# To get help on a function you can type it's name followed by '?' to print the functions docstring. \n",
    "# Adding '??' to the end of the function name will print the raw python code so you can look in detail what the function is doing 'under the hood'\n",
    "\n",
    "#stats.linregress??\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print(\"slope: %f, intercept: %f\" % (slope, intercept))\n",
    "print(\"R-squared: %f\" % r_value**2)\n",
    "\n",
    "# Plot the data with a trend line\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df.index[0]+delta, y, 'o', label='original data')\n",
    "plt.plot(df.index[0]+delta, intercept + slope*x, 'r', label='fitted line')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Temperature trend at Dunstaffnage is {} degrees per decade'.format(round(slope,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6d687",
   "metadata": {},
   "source": [
    "As an example of singnal processing using SciPy, we will calculate the discrete Fourier transform on our average temperature data using the SciPy FFTpack module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89055da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "import datetime\n",
    "\n",
    "data = df['tavg'].interpolate().dropna() # first clean the data by interpolating missing points and removing any remaining NaN's\n",
    "\n",
    "#print(data.values) # sometimes need to extract data from a structure using .values\n",
    "#print(data)\n",
    "\n",
    "temp_fft = sp.fftpack.fft(data.values) # Return discrete Fourier transform\n",
    "\n",
    "temp_psd = np.abs(temp_fft) ** 2\n",
    "\n",
    "fftfreq = sp.fftpack.fftfreq(len(temp_psd), 1. / 12) # sample frequencies for monthly data\n",
    "\n",
    "i = fftfreq > 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax.plot(fftfreq[i], 10 * np.log10(temp_psd[i]))\n",
    "ax.set_xlim(0, 5)\n",
    "ax.set_xlabel('Frequency (1/year)')\n",
    "ax.set_ylabel('PSD (dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5bc37",
   "metadata": {},
   "source": [
    "Because the fundamental frequency of the signal is the yearly variation of the temperature (the seasonal cycle), we observe a clear peak at f=1 cycle/year. \n",
    "\n",
    "We can cut out frequencies higher than the fundamental frequency and perform an inverse FFT to convert the modified Fourier transform back to the temporal domain. This way, we recover a smoothed version of the signal (because the fast variations have been lost when we removed the high frequencies in the Fourier transform) that mainly contains the fundamental frequency, as shown in the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fft_bis = temp_fft.copy()\n",
    "temp_fft_bis[np.abs(fftfreq) > 1.1] = 0\n",
    "\n",
    "temp_slow = np.real(sp.fftpack.ifft(temp_fft_bis))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "#data.plot(ax=ax,color='b',lw=1.0, label='Original signal')\n",
    "ax.plot(data, color='b', linewidth=1.0)\n",
    "ax.plot(data.index,temp_slow, 'Orange', '-')\n",
    "ax.set_xlim(datetime.date(1994, 1, 1),datetime.date(2000, 1, 1))\n",
    "ax.legend(['Origional signal','Filtered signal'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Mean temperature')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972bde0",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca475d1",
   "metadata": {},
   "source": [
    "Lets finish by calculating some comparison statistics from the dataset. We will first plot the correlation matrix across all variables in the dataframe using Pandas inbuilt pairwise correlation of columns function. This exploratory data analysis will inform how we then progress with analysing the data in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44645109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlation matrix across all variables in dataframe\n",
    "\n",
    "print('Correlation matrix: \\n{}'.format(df.corr()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544fe85",
   "metadata": {},
   "source": [
    "We see that there is a relativly strong negative correlation of -0.64 between sunlight hours and rainfall (as you might expect!). \n",
    "\n",
    "We can dig into this relationship a little deeper using NumPy and SciPy to calculate the comparison statistics and fit a linear regression to compare the observed monthly sunlight hours with the monthly rainfall total for the decade 1987-1997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85587251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and clean sunhours and rain between 1987 and 1997\n",
    "\n",
    "columns=['sunhours','rain']\n",
    "data=df[columns]['1987':'1997'].interpolate().dropna() \n",
    "\n",
    "plt.scatter(data['sunhours'].values,data['rain'].values)\n",
    "plt.xlabel('Hours of Sunshine per month')\n",
    "plt.ylabel('Precipitation [mm/month]')\n",
    "\n",
    "# Compare the correlations calculated by NumPy and SciPy methods\n",
    "\n",
    "x = data['sunhours'].values; y = data['rain'].values # get raw data arrays\n",
    "\n",
    "r = np.corrcoef(x, y) # NumPy correlation coefficient\n",
    "print('NumPy Corelation coefficient = {}'.format(r[0, 1]))\n",
    "\n",
    "from scipy import stats\n",
    "r = stats.pearsonr(x, y) # SciPy Pearson correlation coefficient and p-value. See 'stats.pearsonr?' for more detail\n",
    "print('SciPy Pearson R = {}'.format(r[0])) \n",
    "\n",
    "# Print linear regression results\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "print('Regression slope = {}'.format(result.slope))\n",
    "print('Regression intercept = {}'.format(result.intercept))\n",
    "print('Regression pvalue = {}'.format(result.pvalue))\n",
    "print('Regression standard error = {}'.format(result.stderr))\n",
    "print('Regression R^2 = {}'.format(result.rvalue**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ada8b",
   "metadata": {},
   "source": [
    "From this comparison it seems reasonable to assume that months with more sunlight hours will have less rainfall; looking at the R^2 value, 35% of the variance in rainfall can be explained by variability in sunlight. We will now take this a little further and see if we can predict rainfall from sunlight hours by fitting a linear regression model from the scikit-learn module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7a00a",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07812f80",
   "metadata": {},
   "source": [
    "Scikit-learn (or sklearn) is a powerful module designed for machine learning in Python. Sklearn is built on NumPy, SciPy, and matplotlib and provides simple and efficient tools for predictive data analysis. Below we will fit a linear model to the data (similar to what we did above using SciPy) but then use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525da002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = x[:, np.newaxis] # Use only one feature\n",
    "\n",
    "reg = LinearRegression().fit(X, y) # Sanity check: The values below should look very similar to the values calculated using the SciPy stats.linregress method above.\n",
    "print('Regression R^2 = {}'.format(reg.score(X, y)))\n",
    "print('Regression slope: {}'.format(reg.coef_[0]))\n",
    "print('Regression intercept: {}'.format(reg.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0d748",
   "metadata": {},
   "source": [
    "Notice that the slope and intercept are nearly identical to the values calculated using the SciPy method (good news!). We can now divide the data into a training and test set and use scikit-learn to fit a linear model to the training set and use the test set to assess the accuracy of the predictions (and, finally, make a prediction of monthly precipitation from sunlight hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31db763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a predictive regression model \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = x[:, np.newaxis] # Use only one feature\n",
    "\n",
    "# Splitting the datasets into training and testing sets (you could do this manually, i.e. X_train = X[:-20])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.3)\n",
    "\n",
    "# Create linear regression object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test, color=\"black\", label='observations')\n",
    "plt.plot(X_test, y_pred, color=\"blue\", linewidth=3, label='prediction')\n",
    "plt.xlabel('Sunlight hours per month')\n",
    "plt.ylabel('Precipitation [mm/month]')\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "# Running Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "predictions = model.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r^2 is: ', r2)\n",
    "print('The RMSE is: ', rmse)\n",
    "\n",
    "# Make a prediction\n",
    "\n",
    "monthly_sunhours = 100\n",
    "prediction = model.predict(np.array([[monthly_sunhours]]))[0]\n",
    "print('For a month with {} hours of sunlight, I would predict there to be {} mm of rain'.format(int(monthly_sunhours),np.round(prediction,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f70439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
